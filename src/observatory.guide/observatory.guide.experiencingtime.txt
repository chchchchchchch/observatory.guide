%__NOPUBLISH__

% HEADER: How humans and machines negotiate the experience of time

The experience of time is an essential element of any form of experience or cognition. Emotions depend to a large extent on expectations, or the potential coming of a future event. Any observing or experience of difference, of presence related to an earlier or later absence, is linked with an experience of time.
However, how the actual experience of time is shaped is strongly influenced by all sort of design decisions and implementations, both for humans and machines. Also, the experience of time is a conglomerate of different experiences: time as a common moment, the duration of a certain time, time as cyclic events, historical time, and so on. Researching how humans and machines experience time and negotiate their time experiences is therefore an interesting avenue to explore.

Humans have developed a time experience which was linked to natural life cycles, but it has been influenced by both technology and social conditions.(% CARLINSAYS: suggested rewording: "Humans have developed a time experience that is linked to natural life cycles but that is also influenced by both technology and social conditions.")
The first time cycle is the day-night time cycle. Humans do their stuff during the day, but need to sleep. The night is generally the preferred time for sleep, but the availability of artificial light and the need for longer-distance coordination has influenced how humans deal with the day cycle and the place for sleep in it.
Time measurement also developed: early time measurement was linked to observation of natural circumstances like sunrise and sunset. (% CARLINSAYS: I suggest cutting "Time measurement also developed" and starting with"Early time measurement was linked to the day-night cycle through observation of natural circumstances like sunrise and sunset.") Measurement of such sun cycles (which is in fact an earth cycle) through sundials allowed for more precise time referencing, but it is very place and season dependent. More light during summer than winter implied that hours were longer in summer than in winter. Similarly such changes were greater at higher latitudes, while near the equator such changes are limited. In other words, time measured by sundials provided a local common reference of time, but not one over longer distances.

This seasonal time experience when the human world was flat reflects the unknown spherical geometry of the earth cycle projected on the flat earth. When humans became aware of earth as a sphere, they responded by flattening and linearising time. Mechanical clocks allowed to unify time lengths and thereby also standardize time. Physical observation and all sorts of economic processes needed such standardized time measurement. Early versions of such time measurement, like hourglasses, existed but remained disconnected from day time measurement. Mechanical clocks allowed to unify different time cycles and scales. It also allowed standardization of time over longer distances, departing from the local sundial time to time zones, which were less strictly linked to the seasonal rhythm of the sun but more to geographical zones. Long distance trade, industrialization and later long-distance communication by electro-magnetic signals (comparable to the speed of light) demanded more geographical coordination. In the nineteenth century, coordination developed through clock networks, with a master clock driving the slave clocks. Nowadays we work with atomic clocks and a global Coordinated Universal Time or UTC as a reference to which geographical time zones are connected. Humans organize their activities accordingly, if necessary by de-linking from the solar rhythm. The borders of time zones diverge very often from the longitudinal lines for economic and political reasons.
A similar socialisation and globalisation of time occurred for computers. Where in the early computer age time was set and counted locally by each machine, it is now common to continuously synchronize time over the Internet through time servers and the Network Time Protocol. Humans get woken, cron jobs get triggered, precision bombs get guided, and trains count their delays in measure with the drill signal of the Master Clock of the US Naval Observatory, only differing by tiny variations in latency times. 

Humans have also developed ways to relate to time on longer scales, which were originally linked to natural rhythms: years, life cycles. Calendar systems were (% CARLINSAYS: "are used"? the tense of verbs and the use of the passive voice in this make certain sentences read a little strangely) used to determine seasonal agricultural needs (when to plant, when to harvest), while they also made it possible to keep track of life cycles and historical time. Again, such calendar systems have been very diverse and local, but have been slowly fused to a couple of dominant models. 
Generational or birth, life, and death rhythms, originating from the human experience, have been projected on all sorts of phenomena. Religions tried (% CARLINSAYS: "try" or "tried and continue to try") to explain the origin of everything, while also often predicting the end in apocalyptic visions. The demise of religion at the hand of science did not let such generational visions disappear. They got new expressions in scientific theories of the beginning (big bang, evolution) and end (the heath death of the universe, the end of the earth at the final burnout phase of the sun) of everything. Similar apocalyptic visions are now embedded through technological design decisions (Y2K, the end of Unix-time in 2038). In all versions the end is often linked to the specific design of time (e.g. the end of the Maya calendar, millenarian movements). But just like religious visions can extend their apocalypse in a new versions (e.g. the always near but always delayed apocalypse of the Saints of the last days), machinic accounts of time can always be extended by enlarging the bit size of the time range (cfr the extension of Unix time till AD 292277026596, or safely after the end of the observable universe according to contemporary physics).

## The time(s) of the machine

Machines also have their natural cycle: the vibrating pulses of the internal crystal clock drives the cycles according to which the processor works. All PCs have such a Real Time Clock (RTC), independent of the processor. The time of the computer is linked to this clock cycle, as it consists in counting cyclical ticks. This produces a single cyclical, and completely linear, time rhythm in the hardware. In contrast to the earthly or natural cycles it is without any seasonal difference or interference between several cycles. This makes a computer into a monadic time capsule, disconnected from the outside rhythms.
The time experience in the software is in principle based on this local time cycle. However, once computers and software gets linked and networked, they have to negotiate and synchronize their times.
To start, time in a computer is no unique or unified experience. Several hardware components and a diverse collection of software organised in layers and processes create a whole ecology of interdependent time experiences. The operating system experiences other software components, and users through them, as a bunch of processes screaming for attention. One of the most pushy interrupts is the timer forcing the processor to count another click and update the system time. An internal kernel process performs the negotiation of time through which the clock count is linked with a system time. 
This starts already during the booting process, when the operating system is determining the clock signal frequency. PCs have another time-measuring device, the Programmable Interval Timer
(PIT), which can be set by the processor at a defined frequency. During a short time indicated by this PIT, the clock cycles of the RTC get counted and the frequency of the RTC gets calculated. Several other timing devices are present in the hardware, synchronized by kernel processes into a range of times available for the operating system and the processes. As said, one of these times is available as system time and gets communicated to all other processes when demanded. 
With the advent of the Internet computers are not monads anymore, but are socialized in the common rhythm broadcasted with the Network Time Protocol. The local system time serves as back up, but gets continuously adapted to the network time. On a Ubuntu/Debian machine these times can be checked with timedatectl status. The timedatectl command enables to change these synchronisation processes. The actual synchronisation is done by the timesyncd process and the time servers to be used can be set in the /etc/systemd/timesyncd.conf file. Other Linux flavours work with the older ntp process which can be configured in /etc/ntp.conf. 

The actual process time is completely different from this system time. Most of the time processes are put on hold and when the scheduler gives them time they can proceed till the next on hold is forced to make time for another process. The scheduler is the big organizer of time in the internal ecology of processes.
System time is externally counted and therefore an external global variable to these processes. They (% CARLINSAYS: they refers to the processes? if not then clarify) can all send a demand to the kernel to get the system time. This gets communicated through the software stack with a range of system calls of the kernel and through the specific time modules of the programming language the software is programmed in.
The difference between the actual process time and system time does not appear in how time is perceived by the process. The process only perceives time as the difference between two demands of system time and is oblivious of its time being put on hold. The processor on the other hand spent most of its processing time as idle time: a processor is doing time waiting for slow system components like memory and even slower hard drives and network connections to respond and switches between checking for responses of these laggards. L’enfer du temps perdu, ce sont les autres.

Connecting computers into a network demands new negotiations of time. We already mentioned the networked and globalised UTC timekeeping. But temporal negotiations happen on all levels of the system. Network protocols have timed choreographies to make connections and proceed with communications, with time out failsafes to break off when something goes wrong. The timing of an action is an essential component making the difference between a meaningful signal and noise.
Using a browser over http to connect to a website, or better (% CARLINSAYS: better is meant to mean it is a better example? if so cut the word.) the server providing the website on your request, is built on a discontinuous time practice. In a REST architecture the server just deals with a queue of requests and does not see continuity over time between certain requests from a single user.  New temporal practices have been designed and technically implemented. Through cookies the server is able to recognise users and their state in time. 
The border between your computer and servers on the internet becomes fuzzy when external software is dropped on your computer and runs in your webbrowser. Javascript modules get dropped on your computer and can start performing tasks on demand of an external server, be it rendering a graph or mining digital money. Similarly, the browser becomes a border where time gets negotiated through synchronisation processes.
What time exactly is depends on the task at hand. Each tool contains its specific temporal practices, dependent on the speed and subject matter of the synchronization process needed.
For example, for collaborative document editing tools like Google Docs or Etherpad it is a sequence of versions of the document. A range of strategies have been developed to allow to synchronize the changes made by different users with the least amount of conflict. 
The Easysync-protocol used by Etherpad constructs a document from changesets. A changeset details the edits made by a user or the difference with the former local version of the text. In other words, the flow of time is represented through a series of changesets which can be summed to the present state. The server keeps a sequence of acknowledged changesets. These acknowledged changesets represent the current common state and get communicated to all clients. 
Locally each client builds its present state by summing up the acknowledged changesets received from the server, and with the local changesets which are not yet acknowledged. Each client communicates its local changesets, every 500 ms after the latest acknowledgment.  As this changeset can be relative to an earlier version the server first recalculates a changeset relative to the current version. Then it sends an acknowledgment to the sender and the changeset to the other clients. 
Different collaborative document editing tools use different methods to deal with conflicts, which also are dependent on the purpose or content of the document. Conflicts between numeric edits in a collaborative spreadsheet are dealt with differently than conflicts between text edits. But what is common to both is that the present gets continuously constructed on the server and on the clients and negotiated through the specific protocol. The user can always access its local copy of the text and create its local present, but this local present then gets negotiated with the server to create a common present. (% CARLINSAYS:These last two sentences are key and could be clearer. I have tried an edit that maybe does so?)
And every tool rings also its own disasters and apocalyptic experiences through the collapse of the negotiation process and thereby of the common state.

This negotiation of time is in the first place a negotiation of the present. But also what is past and future gets constructed in this present. The ordered sequence connected to the system time(s) already imply such a past and future. But the construction of a past consists also of a negotiation of what remains and what gets forgotten. Data gets stored in memory or written to storage devices, while the operating systems assigns time stamps to these traces of the present becoming past and writes other traces to a range of log files. 
As writers trying to capture their stream of consciousness already experienced, it is impossible to completely store the present for future use as past. There will always be a remainder that escapes and can not be written down. Similarly an operating systems can not keep a log of all its operations without getting stuck in an infinite regress in which it tries to log its logging operations. What will be the past for a future present needs to be constructed and selected. Everything else gets forgotten.
Linux stores its logs in /var/log, while all sorts of programs can create their own logs. All these logs are specific histories, for example of what programs got installed. To get an idea of your past on a Linux system in the file system, you can collect the timestamps of all files with:

% -----------------

os.system("ls -R -l --time-style=long-iso \
           > modlistsystem-long-iso.txt")
os.system("ls -R -lu --time-style=long-iso \
           > accesslistsystem-long-iso.txt")

% SRCCODE:

## Renegotiating time with your computer: sundial network time.

Technology has been a tool through which humans create distance from natural cycles and design their own time experiences. This means we can critically intervene in the functioning of the technology and develop alternative time practices and experiences. As an example we put forward as a not-yet-existing-proof of concept the possibility to let the computer work according to sundial time.
Is it possible to reconfigure the time of the computer and rewire the connections with human and natural rhythms? Would we be able to let the computer function in an older human time experience, e.g. the time of the sundial? How can such sundial experience be built into the system and what would be the impact on the user?
Sundial time is a geographically and seasonally localised time. It also includes a distinction between day and night. The night is ‘out of time’. This distinction has been extradited from linear time practices, where the amount of light is just a variable external to steady beat of time. Linear time turns the night into economically productive time. Running your computer on sundial time re-introduces the night in your system.

An intervention to introduce sundial time in your computer is possible in the whole range of places we discussed where time gets negotiated. The most fundamental but also most difficult route would be to exchange the clock with something reflecting a more natural rhythm. However, as we have seen that this clock has become only a back up tool and that the actual system time is always renegotiated with other systems connected through the network, another renegotiation process can be introduced. Therefore, the most easy way to introduce sundial time would be to reconfigure the timesyncdor ntp processes and make them listen to an alternative sundial time server. Such a sundial time server can be built in different ways. A hardware version can be made of a sundial combined with light sensors, measuring the location of the shadow through the difference in light and deriving the sundial time from this location. This would link the time server to the actual earthly day and night cycle. A simulated version could be a local piece of software which looks up the timing of sunrise and sunset at the specific location and day. Based on this information it recalculates the local sundial time, which it provides through the NTP protocol. The local computer receives this sundial time from the nearest sundial time server and continuously adapts its system time, as it does now already based on UTC. Further, it can be programmed to go into sleep modus during the night and to wake up only when a sunrise signal is received from the time server.

Letting a computer run on sundial time is a conscious effort to disconnect it from human-made linear time and to reconnect it with the old earth-driven cycles and the ancient time experience by humans. The unified time of UTC and the time zones gets broken up into extremely localized time servers, and the difference between day and night gets introduced into the functioning of the computer. 
This re-enactment of such cycles through the computer will remind human users that the experience of time is a socially negotiated and technically implemented experience. Further, a computer running on sundial time would be a great piece of nannyware nudging the user to live in harmony with his natural environment and a synchronization tool to re-establish the link between the users bio-rhythm and the earthly day and night cycle. It would also be a great reminder why humans tried in the first place to escape from these earthly rhythms through technology and started hacking time.

Hans Lammerant, January 2018

% NOTE: -
 This text was written in and in resistance/conflict to WTC time, which is exemplary for the bureaucratic office time experience. The WTC building boots up at 9AM and is turned off in several steps (at 5PM the air conditioning is turned off, later entrances close) into a wake state. The concierge can let you in and out through the night side entry, but main life support systems remain turned off outside office hours. This wake state continues during the weekend, turning the building into a glass house with limited air in storage. On Monday morning this bureaucratic time capsule revives from its slumber. A suffocating experience, but actually the building is a great piece of nannyware nudging towards a healthy office rhythm without too much extra hours outside the herd work ethic.

Such office time can also be implemented and negotiated on your local computer. A small Proof of Concept was the adapted bashrc on the etherbox simulating a system getting bored and stealing time. This can be further developed by including a differentiated response during versus outside office hours, aging (slower when timestamp of original install is more remote in time), etc.

